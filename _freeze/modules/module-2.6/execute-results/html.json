{
  "hash": "a6fe9d6f48b821a7b128fa35215dd19f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Module 2.6\"\nsubtitle: \"Cleaning Data\"\nformat: \n  html:\n    code-link: true\nhighlight-style: atom-one\nexecute: \n  echo: true\n  message: false\n  warning: false\n---\n\n::: {.callout-tip}\n## Prework\n\n- Start a QMD file for this module. (At this point, I assume you know how to create a QMD file in a project and set the YAML header. So this will be the last time I mention it.)\n- Install the [janitor](https://sfirke.github.io/janitor/articles/janitor.html) package and have a look at the documentation.\n:::\n\n## Overview\n\nIn this module we are going to focus on how to clean up messy real world data. We are going to do this using data downloaded from the [World Development Indicators](https://databank.worldbank.org/source/world-development-indicators). This will be our third iteration of working with World Bank data, so if you are a budding economist you are in luck! The first time we encountered World Bank data was through the `WDI` package where the data were tidy just by virtue of being accessed through the API. In the last module, we left off with a worked example where we used the `tidyr` version of some untidy World Bank's World Development Indicators (WDI) dataset and transposed it to make it into a tidy dataset. In this lesson, we are going to download data directly from the WDI interface that is not only untidy but also contains some other issues that we will need to address.\n\n## Downloading and Reading in the Data\n\n{{< video https://youtu.be/ZwJsSjJRuMU title=\"Reading Data into R\" >}}\n\nGo to the World Development Indicators [portal](https://databank.worldbank.org/source/world-development-indicators) at the World Bank's Data Bank.\n\nUnder Countries, select the Countries tab and then select the little check mark ‚òëÔ∏è to select all of the countries. Be sure to select the Countries tab first, though, or you will also be downloading aggregate data for regions and groups of countries.\n\nNext, under Series, search for \"labor force participation\" and find labor force participation rates for women ages 15-64 (ILO modeled estimates). Check that series. \n\nNow go to Time and select the years from the last 50 years. Click Apply Changes, go to Download Options and download as a .csv file. Place the .csv file in the data directory that you created for this module. Save it as \"messy_wb_data.csv\" or something like that. \n\nNow we are going to read this messy World Bank data into R using the `read_csv()` function from the `readr` package.After we have read the data  into R, we are going to have a look at it with `glimpse()`.\n\n::: {.callout-note}\n## Did You Know?\nWhile comma delimited files are the most common kind of flat file, `readr` includes functions for parsing files with a wide range of delimiters including tabs (`read_tsv()`), semicolons (`read_csv2()`) and white spaces (`read_table()`). There is also a Tidyverse package for reading in Excel files called [readxl](https://readxl.tidyverse.org/).\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readr) \nlibrary(dplyr) \n\nwb_data_messy <- read_csv(\"data/messy_wb_data.csv\")\n\nglimpse(wb_data_messy)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 222\nColumns: 54\n$ `Country Name`  <chr> \"Afghanistan\", \"Albania\", \"Algeria\", \"American Samoa\",‚Ä¶\n$ `Country Code`  <chr> \"AFG\", \"ALB\", \"DZA\", \"ASM\", \"AND\", \"AGO\", \"ATG\", \"ARG\"‚Ä¶\n$ `Series Name`   <chr> \"Labor force participation rate, female (% of female p‚Ä¶\n$ `Series Code`   <chr> \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI‚Ä¶\n$ `1972 [YR1972]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1973 [YR1973]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1974 [YR1974]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1975 [YR1975]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1976 [YR1976]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1977 [YR1977]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1978 [YR1978]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1979 [YR1979]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1980 [YR1980]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1981 [YR1981]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1982 [YR1982]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1983 [YR1983]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1984 [YR1984]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1985 [YR1985]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1986 [YR1986]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1987 [YR1987]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1988 [YR1988]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1989 [YR1989]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `1990 [YR1990]` <chr> \"15.83\", \"60.63\", \"12.31\", \"..\", \"..\", \"76.73\", \"..\", ‚Ä¶\n$ `1991 [YR1991]` <chr> \"15.89\", \"65.54\", \"12.33\", \"..\", \"..\", \"76.69\", \"..\", ‚Ä¶\n$ `1992 [YR1992]` <chr> \"15.92\", \"66.56\", \"12.37\", \"..\", \"..\", \"76.66\", \"..\", ‚Ä¶\n$ `1993 [YR1993]` <chr> \"15.91\", \"65.01\", \"12.41\", \"..\", \"..\", \"76.68\", \"..\", ‚Ä¶\n$ `1994 [YR1994]` <chr> \"15.88\", \"63.64\", \"12.47\", \"..\", \"..\", \"76.64\", \"..\", ‚Ä¶\n$ `1995 [YR1995]` <chr> \"15.92\", \"61.59\", \"12.56\", \"..\", \"..\", \"76.57\", \"..\", ‚Ä¶\n$ `1996 [YR1996]` <chr> \"15.75\", \"60.28\", \"12.64\", \"..\", \"..\", \"76.55\", \"..\", ‚Ä¶\n$ `1997 [YR1997]` <chr> \"15.59\", \"61.91\", \"12.59\", \"..\", \"..\", \"76.53\", \"..\", ‚Ä¶\n$ `1998 [YR1998]` <chr> \"15.47\", \"60.62\", \"12.59\", \"..\", \"..\", \"76.53\", \"..\", ‚Ä¶\n$ `1999 [YR1999]` <chr> \"15.4\", \"58.87\", \"12.63\", \"..\", \"..\", \"76.51\", \"..\", \"‚Ä¶\n$ `2000 [YR2000]` <chr> \"15.35\", \"57.89\", \"12.71\", \"..\", \"..\", \"76.49\", \"..\", ‚Ä¶\n$ `2001 [YR2001]` <chr> \"15.5\", \"56.71\", \"12.85\", \"..\", \"..\", \"76.48\", \"..\", \"‚Ä¶\n$ `2002 [YR2002]` <chr> \"15.7\", \"56.06\", \"13.02\", \"..\", \"..\", \"76.44\", \"..\", \"‚Ä¶\n$ `2003 [YR2003]` <chr> \"15.92\", \"55.3\", \"13.24\", \"..\", \"..\", \"76.41\", \"..\", \"‚Ä¶\n$ `2004 [YR2004]` <chr> \"16.13\", \"54.57\", \"13.5\", \"..\", \"..\", \"76.38\", \"..\", \"‚Ä¶\n$ `2005 [YR2005]` <chr> \"16.33\", \"53.88\", \"13.79\", \"..\", \"..\", \"76.36\", \"..\", ‚Ä¶\n$ `2006 [YR2006]` <chr> \"16.12\", \"53.43\", \"14.12\", \"..\", \"..\", \"76.39\", \"..\", ‚Ä¶\n$ `2007 [YR2007]` <chr> \"15.91\", \"53.07\", \"14.47\", \"..\", \"..\", \"76.42\", \"..\", ‚Ä¶\n$ `2008 [YR2008]` <chr> \"15.74\", \"52.78\", \"14.87\", \"..\", \"..\", \"76.46\", \"..\", ‚Ä¶\n$ `2009 [YR2009]` <chr> \"15.65\", \"51.57\", \"15.31\", \"..\", \"..\", \"76.53\", \"..\", ‚Ä¶\n$ `2010 [YR2010]` <chr> \"15.65\", \"52.75\", \"15.49\", \"..\", \"..\", \"76.59\", \"..\", ‚Ä¶\n$ `2011 [YR2011]` <chr> \"16\", \"60.59\", \"16.45\", \"..\", \"..\", \"76.67\", \"..\", \"55‚Ä¶\n$ `2012 [YR2012]` <chr> \"16.44\", \"55.1\", \"17.48\", \"..\", \"..\", \"76.73\", \"..\", \"‚Ä¶\n$ `2013 [YR2013]` <chr> \"17.42\", \"50.58\", \"18.29\", \"..\", \"..\", \"76.79\", \"..\", ‚Ä¶\n$ `2014 [YR2014]` <chr> \"18.46\", \"50.18\", \"16.68\", \"..\", \"..\", \"76.83\", \"..\", ‚Ä¶\n$ `2015 [YR2015]` <chr> \"19.55\", \"54.05\", \"17.5\", \"..\", \"..\", \"76.87\", \"..\", \"‚Ä¶\n$ `2016 [YR2016]` <chr> \"20.7\", \"56.4\", \"18.33\", \"..\", \"..\", \"76.9\", \"..\", \"56‚Ä¶\n$ `2017 [YR2017]` <chr> \"21.91\", \"55.54\", \"19.19\", \"..\", \"..\", \"76.91\", \"..\", ‚Ä¶\n$ `2018 [YR2018]` <chr> \"22.32\", \"59.12\", \"18.95\", \"..\", \"..\", \"76.9\", \"..\", \"‚Ä¶\n$ `2019 [YR2019]` <chr> \"22.74\", \"61.46\", \"18.7\", \"..\", \"..\", \"76.88\", \"..\", \"‚Ä¶\n$ `2020 [YR2020]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n$ `2021 [YR2021]` <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", ‚Ä¶\n```\n\n\n:::\n:::\n\n::: {.callout-warning icon=false}\n## Your Turn!! \n\nFollow along with the video and the steps described avove to download the data and read it into R.\n:::\n\n## Reshaping the Data\n\n{{< video https://youtu.be/u4AXi8A1Bqo title='Reshaping Data With `pivot_longer()`' >}}\n\nRecall from the last module that in order for the data to be tidy, we want each column to represent a variable and each row to represent an observation. \n\nBut here again we see that the World Bank data are in *wide form*, meaning that each column represents a year and each row represents a country. This entails that each row represents *multiple* observations, violating tidy principles. \n\nTo rectify this, we need to *reshape* the data from wide form to *long form* using `pivot_longer()`](https://tidyr.tidyverse.org/reference/pivot_longer.html) function from the [tidyr](https://tidyr.tidyverse.org/index.html) package`. Recall that the `pivot_longer()` function takes three basic arguments: \n\n- **cols** - which columns you want to pivot\n- **names_to** - the name of the column where the old column names are going to\n- **values_to** - the name of the column where the values are going to \n\nIn our case, we want to reshape all of the year columns and have the years represented in the rows. We want the newly created column to be called \"year\" and the values are going to represent the data on female labor force participation we downloaded (female labor force participation rates).\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load tidyr\nlibrary(tidyr)\n\nwb_data <- wb_data_messy |> \n  pivot_longer(         \n    cols = `1972 [YR1972]`: `2021 [YR2021]`,\n    names_to = \"year\", \n    values_to = \"flfp\" \n  ) \n\nglimpse(wb_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 11,100\nColumns: 6\n$ `Country Name` <chr> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanist‚Ä¶\n$ `Country Code` <chr> \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\",‚Ä¶\n$ `Series Name`  <chr> \"Labor force participation rate, female (% of female po‚Ä¶\n$ `Series Code`  <chr> \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.‚Ä¶\n$ year           <chr> \"1972 [YR1972]\", \"1973 [YR1973]\", \"1974 [YR1974]\", \"197‚Ä¶\n$ flfp           <chr> \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"‚Ä¶\n```\n\n\n:::\n:::\n\nNotice that when we specify the years in our `pivot_longer()` call we encapsulate them in backticks (``). This is because the years, as they were imported from the WDI dataset, have spaces in them. Typically we want to avoid this scenario by writing our variable names in [*snake_case*](https://en.wikipedia.org/wiki/Snake_case). \n\n::: {.callout-warning icon=false}\n## Your Turn!! \n\nFollow along with the video and the steps described above to reshape the data. Make sure to note and use backticks \nwhen specifying the years in the `pivot_longer()` call.\n:::\n\n## Cleaning up Our Data\n\n{{< video https://youtu.be/xa0tYCfHHTI title='Cleaning Data in R' >}}\n\nNow that our data are transposed, we can start to clean up a few remaining issues. For example, the `year` variable is stored as a character string that includes both the year and a redundant label in brackets‚Äîe.g., `\"1972 [YR1972]\"`. In addition, the variable `flfp` (female labor force participation) is stored as a character when it should be numeric.\n\nTo fix these issues, we‚Äôll use the `mutate()` function from `dplyr`. First, we call `mutate()` along with `substring()` to extract just the first four characters from the `year` column. Then, we use the `across()` function inside `mutate()` to convert both `year` and `flfp` to numeric.\n\n::: {.cell}\n\n```{.r .cell-code}\nwb_data <- wb_data |> \n  mutate(year = substring(year, 1, 4)) |>  \n  mutate(across(c(\"year\", \"flfp\"), as.numeric))  \n\nglimpse(wb_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 11,100\nColumns: 6\n$ `Country Name` <chr> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanist‚Ä¶\n$ `Country Code` <chr> \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\",‚Ä¶\n$ `Series Name`  <chr> \"Labor force participation rate, female (% of female po‚Ä¶\n$ `Series Code`  <chr> \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.‚Ä¶\n$ year           <dbl> 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1‚Ä¶\n$ flfp           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n```\n\n\n:::\n:::\n\nThe last thing we are going to do is to fix the variable names. Specifically, we want to remove the spaces from the remaining variables and conver them from title case to snake case. To do this, we will use the `clean_names()` function from the `janitor` package. \n\nAs a final step, we can export our clean data to a new .csv file with the `write.csv()` function from `readr`. \n\n::: {.cell}\n\n```{.r .cell-code}\n# Load janitor\nlibrary(janitor)\n\nwb_data_clean <- wb_data |>  \n  clean_names() \n\nwrite_csv(wb_data_clean, \"data/wb_data_clean.csv\")\n\nglimpse(wb_data_clean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 11,100\nColumns: 6\n$ country_name <chr> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan‚Ä¶\n$ country_code <chr> \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"‚Ä¶\n$ series_name  <chr> \"Labor force participation rate, female (% of female popu‚Ä¶\n$ series_code  <chr> \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE.ZS\", \"SL.TLF.ACTI.FE‚Ä¶\n$ year         <dbl> 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 198‚Ä¶\n$ flfp         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N‚Ä¶\n```\n\n\n:::\n:::\n\n::: {.callout-warning icon=false}\n## Your Turn!!\n\nFollow along with the video and the steps described above to clean up the data. Use `mutate()` and `across()` to:\n\n- Truncate the `year` variable so that it only includes the four-digit year,\n- Convert `year` and `flfp` to numeric using `across()` inside `mutate()`.\n\nThen, use `clean_names()` from the `janitor` package to clean up the variable names‚Äîremoving spaces and converting to snake_case. Finally, export your cleaned dataset to a new `.csv` file using `write_csv()` from the `readr` package.\n\nüí° **Challenge yourself!**  \nDownload a new dataset from the World Bank with more than one variable. Use `pivot_longer()` and `pivot_wider()` to reshape the data, then follow the steps above to clean and prepare it for analysis.\n:::\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}